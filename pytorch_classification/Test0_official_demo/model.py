# 定义了LeNet
import torch.nn as nn
import torch.nn.functional as F

"""
 定义类：类中包括属性、构造方法
 而 __init__(self)将类的实例作为参数，直接完成了类的属性的定义和构造方法
 class MyClass:
    def __init__(self, attribute1, attribute2):
        self.attribute1 = attribute1
        self.attribute2 = attribute2
    def method(self):
        # 使用属性
        print(self.attribute1)
        print(self.attribute2)
# 创建类的实例并初始化属性
my_object = MyClass("Value 1", "Value 2")
# 调用方法访问属性
my_object.method()

构造函数的名称是固定的__init__，而属性的定义可以在类的任何地方进行，不一定需要在构造函数中定义。
构造函数通常用于初始化对象的属性，但你也可以在其他方法中动态添加属性。
"""


# 首先，定义一个类LeNet，类要继承于nn.Module这个父类
class LeNet(nn.Module):
    # 类中的两个方法之一：初始化函数
    # 作用：创建子模块
    def __init__(self):
        # super函数解决在多重继承中调用父类方法中可能会出现的一系列问题
        # 调用父类的构造函数
        super(LeNet, self).__init__()
        # 3：输入特征层的深度
        # 16：卷积核的数量(输出特征层的深度)
        # 5：卷积核的尺度 5x5
        # 通过 nn.Conv2d来定义卷积层
        self.conv1 = nn.Conv2d(3, 16, 5)
        # 2：池化核的大小
        # 2：步距，不指定的话与池化核大小一样
        # 通过nn.maxpool2d定义下采样层
        self.pool1 = nn.MaxPool2d(2, 2)
        # 第二个卷积层
        self.conv2 = nn.Conv2d(16, 32, 5)
        # 第二个池化层
        self.pool2 = nn.MaxPool2d(2, 2)
        # 全连接层：需要把得到的特征向量给展平：一维向量
        self.fc1 = nn.Linear(32 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        # 使用的训练集具有10个类别的分类任务
        # 以上为一些网络层结构
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # x: [batch，channel，height，width],数据
        # F.relu：激活函数
        x = F.relu(self.conv1(x))  # input(3, 32, 32) output(16, 28, 28)
        x = self.pool1(x)          # output(16, 14, 14)
        # 输出通过下采样函数1层
        x = F.relu(self.conv2(x))  # output(32, 10, 10)
        x = self.pool2(x)          # output(32, 5, 5)
        # 数据通过x.view函数展开成一维向量
        # -1 代表第一个维度，batch
        x = x.view(-1, 32 * 5 * 5) # output(32*5*5)
        # 分别通过两个全连接层及激活函数
        x = F.relu(self.fc1(x))    # output(120)
        x = F.relu(self.fc2(x))    # output(84)
        # 最后通过全连接层3
        # 最后应该接一个softmax，将结果转换为概率分布
        # 在内部已经实现了这个方法，不需要再加softmax了
        x = self.fc3(x)            # output(10)

        return x


# 调试信息
import torch


class Test1:
    # 导入torch包
    input1 = torch.rand([32, 3, 32, 32])  # B C N H
    # 定义一个输入变量，随机生成
    model = LeNet()
    # 实例化我们的模型
    print(model)
    # 打印我们的模型
    output = model(input1)
    # 将数据输入到网络中正向传播
    print(output)
    print(type(output))
    print(output.size())

    # 遍历所有参数
    for param in model.parameters():
        print(type(param), param.size())

"""
<class 'torch.Tensor'>
torch.Size([32, 10]) # B Class
"""

"""
LeNet(
  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=800, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
 
tensor([[-0.1032,  0.0229, -0.1090,  0.0640,  0.0234,  0.0194,  0.0485, -0.0644,
          0.0828,  0.0229],
        [-0.1019,  0.0143, -0.1076,  0.0603,  0.0143,  0.0143,  0.0472, -0.0663,
          0.0862,  0.0243],
        [-0.1008,  0.0103, -0.1067,  0.0675,  0.0248,  0.0094,  0.0589, -0.0649,
          0.0831,  0.0242],
        [-0.1054,  0.0137, -0.1040,  0.0627,  0.0270,  0.0093,  0.0456, -0.0633,
          0.0823,  0.0268],
        [-0.1069,  0.0199, -0.1052,  0.0608,  0.0244,  0.0179,  0.0427, -0.0646,
          0.0827,  0.0244],
        [-0.1042,  0.0193, -0.0983,  0.0647,  0.0234,  0.0156,  0.0467, -0.0626,
          0.0861,  0.0207],
        [-0.1042,  0.0169, -0.1026,  0.0732,  0.0278,  0.0176,  0.0489, -0.0651,
          0.0770,  0.0206],
        [-0.1030,  0.0134, -0.1034,  0.0627,  0.0232,  0.0137,  0.0477, -0.0630,
          0.0804,  0.0233],
        [-0.1071,  0.0174, -0.1044,  0.0618,  0.0209,  0.0086,  0.0546, -0.0678,
          0.0847,  0.0246],
        [-0.1028,  0.0239, -0.1129,  0.0642,  0.0219,  0.0178,  0.0563, -0.0571,
          0.0841,  0.0218],
        [-0.1016,  0.0184, -0.1046,  0.0630,  0.0228,  0.0151,  0.0509, -0.0635,
          0.0816,  0.0197],
        [-0.1057,  0.0153, -0.1050,  0.0581,  0.0224,  0.0128,  0.0456, -0.0636,
          0.0768,  0.0205],
        [-0.0997,  0.0164, -0.1038,  0.0603,  0.0273,  0.0151,  0.0513, -0.0597,
          0.0753,  0.0214],
        [-0.1063,  0.0180, -0.1068,  0.0539,  0.0170,  0.0046,  0.0510, -0.0642,
          0.0806,  0.0217],
        [-0.1063,  0.0167, -0.1147,  0.0669,  0.0201,  0.0139,  0.0491, -0.0618,
          0.0800,  0.0204],
        [-0.1060,  0.0197, -0.1026,  0.0585,  0.0244,  0.0115,  0.0425, -0.0596,
          0.0810,  0.0249],
        [-0.1085,  0.0158, -0.1060,  0.0598,  0.0216,  0.0147,  0.0519, -0.0629,
          0.0817,  0.0223],
        [-0.1078,  0.0164, -0.1015,  0.0605,  0.0232,  0.0073,  0.0502, -0.0638,
          0.0814,  0.0282],
        [-0.1094,  0.0230, -0.1128,  0.0632,  0.0269,  0.0130,  0.0518, -0.0631,
          0.0839,  0.0247],
        [-0.1043,  0.0174, -0.1046,  0.0670,  0.0279,  0.0171,  0.0523, -0.0627,
          0.0796,  0.0228],
        [-0.1094,  0.0111, -0.1037,  0.0579,  0.0204,  0.0184,  0.0467, -0.0645,
          0.0799,  0.0269],
        [-0.1014,  0.0172, -0.1002,  0.0592,  0.0208,  0.0163,  0.0494, -0.0619,
          0.0812,  0.0241],
        [-0.1056,  0.0125, -0.1018,  0.0659,  0.0197,  0.0096,  0.0500, -0.0634,
          0.0852,  0.0223],
        [-0.1069,  0.0238, -0.1117,  0.0587,  0.0216,  0.0112,  0.0523, -0.0651,
          0.0864,  0.0234],
        [-0.1086,  0.0200, -0.1074,  0.0599,  0.0187,  0.0086,  0.0443, -0.0634,
          0.0861,  0.0277],
        [-0.1076,  0.0139, -0.1077,  0.0632,  0.0185,  0.0128,  0.0531, -0.0654,
          0.0813,  0.0255],
        [-0.1044,  0.0176, -0.1087,  0.0617,  0.0248,  0.0111,  0.0527, -0.0601,
          0.0801,  0.0238],
        [-0.1044,  0.0167, -0.1063,  0.0648,  0.0242,  0.0146,  0.0484, -0.0623,
          0.0772,  0.0240],
        [-0.1069,  0.0150, -0.1069,  0.0644,  0.0238,  0.0149,  0.0455, -0.0617,
          0.0774,  0.0197],
        [-0.1106,  0.0185, -0.1027,  0.0655,  0.0229,  0.0128,  0.0507, -0.0611,
          0.0875,  0.0226],
        [-0.1081,  0.0179, -0.1044,  0.0593,  0.0153,  0.0131,  0.0453, -0.0646,
          0.0854,  0.0212],
        [-0.1061,  0.0168, -0.1092,  0.0656,  0.0235,  0.0147,  0.0502, -0.0659,
          0.0850,  0.0242]], grad_fn=<AddmmBackward0>)

"""

"""
<class 'torch.nn.parameter.Parameter'> torch.Size([16, 3, 5, 5])
<class 'torch.nn.parameter.Parameter'> torch.Size([16])
<class 'torch.nn.parameter.Parameter'> torch.Size([32, 16, 5, 5])
<class 'torch.nn.parameter.Parameter'> torch.Size([32])
<class 'torch.nn.parameter.Parameter'> torch.Size([120, 800])
<class 'torch.nn.parameter.Parameter'> torch.Size([120])
<class 'torch.nn.parameter.Parameter'> torch.Size([84, 120])
<class 'torch.nn.parameter.Parameter'> torch.Size([84])
<class 'torch.nn.parameter.Parameter'> torch.Size([10, 84])
<class 'torch.nn.parameter.Parameter'> torch.Size([10])
"""


